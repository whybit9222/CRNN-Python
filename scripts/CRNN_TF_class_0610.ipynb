{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.animation as animation\n",
    "import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(tf.Module):\n",
    "    def __init__(self, p_init, name=\"CRNN\"):\n",
    "        super(CRNN, self).__init__(name=name)\n",
    "\n",
    "        #设置工作目录\n",
    "        self.expr_name = \"4s8r-01\"\n",
    "        self.sys_path = \"W:\\CRNN-TF2.0\\CRNN-TF2.0\"\n",
    "        self.fig_path = str(self.sys_path + \"/results/\" + self.expr_name + \"/figs/\")\n",
    "        self.ckpt_path = str(self.sys_path + \"/results/\" + self.expr_name + \"/checkpoint/\")\n",
    "        self.script_path = str(self.sys_path + \"/scripts/\")\n",
    "        self.exp_path = str(self.sys_path + \"/exp_data/\")\n",
    "\n",
    "        #设置初始参数\n",
    "        self.lb = 1e-8\n",
    "        self.n_epoch = 2500\n",
    "        self.n_plot = 10\n",
    "        self.grad_max = 1e2\n",
    "        self.maxiters = 50000\n",
    "\n",
    "        self.lr_max = 5e-3\n",
    "        self.lr_min = 1e-5\n",
    "        self.lr_decay = 0.2\n",
    "        self.lr_decay_step = 500\n",
    "        self.w_decay = 1e-8\n",
    "\n",
    "        self.llb = self.lb\n",
    "        self.p_cutoff = -1.0\n",
    "        self.R = -1.0 / 8.314e-3\n",
    "\n",
    "        self.l_exp = range(1,15)\n",
    "        self.n_exp = 14\n",
    "        self.l_train = []\n",
    "        self.l_val = []\n",
    "        for i in np.arange(1,self.n_exp+1):\n",
    "            j = self.l_exp[i-1]\n",
    "            if not (j in [2, 6, 9, 12]):\n",
    "                self.l_train.append(i)\n",
    "            else:\n",
    "                self.l_val.append(i)\n",
    "\n",
    "        #导入数据为内置tensor.constant\n",
    "        self.exp_data, self.T0, self.beta, self.ocen = self.load_data()\n",
    "\n",
    "        #设置用到的实验数据\n",
    "        self.current_iexp = 1\n",
    "        self.select_exp(self.current_iexp)\n",
    "\n",
    "        #########################################\n",
    "        self.nr=8\n",
    "        self.ns=4\n",
    "        self.npara = self.nr * (self.ns + 4) + 1\n",
    "        \n",
    "        #p = np.random.randn(npara) * 1.e-2\n",
    "        #p[:nr] += 0.8 # w_b\n",
    "        # nr~nr*(ns+1) vij\n",
    "        #p[nr*(ns+1):nr*(ns+2)] += 0.8 # w_out\n",
    "        #p[nr*(ns+2):nr*(ns+4)] += 0.1 # w_b | w_Ea\n",
    "        #p[-1] = 0.1 # slope\n",
    "        self.p = tf.Variable(p_init, name=\"p\", dtype=tf.float64)\n",
    "        self.update_p(p)\n",
    "\n",
    "        u0 = np.zeros(self.ns)\n",
    "        u0[0] = 1\n",
    "        self.u0 = tf.constant(u0, shape=(self.ns,),dtype=tf.float64)\n",
    "        \n",
    "\n",
    "    # 导入文件\n",
    "    def load_data(self):\n",
    "        T0 = np.zeros(self.n_exp)\n",
    "        beta = np.zeros(self.n_exp)\n",
    "        ocen = np.zeros(self.n_exp)\n",
    "        exp_data = []\n",
    "        for i_exp, value in enumerate(self.l_exp):\n",
    "            filename = str(self.exp_path + \"expdata_no\"+str(value)+\".txt\")\n",
    "            exp_npdata = np.loadtxt(filename)\n",
    "            exp_npdata[:, 2] = exp_npdata[:, 2] / max(exp_npdata[:,2])\n",
    "            if value == 4:\n",
    "                exp_npdata = exp_npdata[:60, :]\n",
    "            elif value == 5:\n",
    "                exp_npdata = exp_npdata[:58, :]\n",
    "            elif value == 6:\n",
    "                exp_npdata = exp_npdata[:60, :]\n",
    "            elif value == 7:\n",
    "                exp_npdata = exp_npdata[:71, :]\n",
    "            T0[i_exp-1] = exp_npdata[0, 1]\n",
    "            exp_tfdata = tf.convert_to_tensor(exp_npdata, dtype=tf.float64)\n",
    "            exp_data.append(exp_tfdata)\n",
    "        T0 = tf.convert_to_tensor(T0, dtype=tf.float64)\n",
    "        beta = tf.convert_to_tensor(np.loadtxt(self.exp_path + \"beta.txt\"), dtype=tf.float64)\n",
    "        ocen = tf.convert_to_tensor(np.log(np.loadtxt(self.exp_path + \"ocen.txt\")+self.llb), dtype=tf.float64)\n",
    "        return exp_data, T0, beta, ocen\n",
    "\n",
    "    # 更新p\n",
    "    def update_p(self, p):\n",
    "        self.p = p\n",
    "        self.w_in, self.w_b, self.w_out = self.p2vec(p)\n",
    "    # 选择要用到的实验数据，将其整理为纯净的tf Tensor\n",
    "    def select_exp(self, i_exp):\n",
    "        self.current_T0 = tf.reshape(self.T0[i_exp-1:i_exp], shape=(1,1))\n",
    "        self.current_exp_data = self.exp_data[i_exp-1]\n",
    "        self.current_beta = tf.reshape(self.beta[i_exp-1:i_exp], shape=(1,1))\n",
    "        self.current_ocen = tf.reshape(self.ocen[i_exp-1:i_exp], shape=(1,1))\n",
    "        self.current_ts = self.current_exp_data[:,0]\n",
    "        self.current_tinit = tf.constant(self.current_ts[0], dtype=tf.float64)\n",
    "\n",
    "    #拆分权重向量\n",
    "    @tf.function\n",
    "    def p2vec(self, p):\n",
    "        slope = p[-1] * 1.e1\n",
    "        \n",
    "        w_b = p[:self.nr] * (slope * 10.0)\n",
    "        w_b = tf.clip_by_value(w_b, clip_value_min=0., clip_value_max=50.)\n",
    "        \n",
    "        # julia 与 tf的reshape函数实现不同\n",
    "        w_out = tf.reshape(p[self.nr:self.nr*(self.ns+1)],shape=(self.nr,self.ns))\n",
    "        w_out = tf.transpose(w_out)\n",
    "\n",
    "        temp1 = tf.clip_by_value(w_out[0:1, :], -3., 0.)\n",
    "        temp2 = tf.clip_by_value(tf.abs(w_out[-1:, :]), 0., 3.)\n",
    "        w_out = tf.concat([temp1, w_out[1:-1], temp2], axis=0)\n",
    "\n",
    "        # 此段省略\n",
    "        # julia原文：\n",
    "        # if p_cutoff > 0.0\n",
    "        #     w_out[findall(abs.(w_out) .< p_cutoff)] .= 0.0\n",
    "        # end\n",
    "\n",
    "        temp3 = -1*(tf.reduce_sum(w_out[:-2,:], 0) + w_out[-1:, :])\n",
    "        temp3 = tf.reshape(temp3, shape=(1,self.nr))\n",
    "        \n",
    "        w_out = tf.concat([w_out[:-2,:], temp3, w_out[-1:,:]], axis=0)\n",
    "\n",
    "        w_in_Ea = tf.abs(p[self.nr*(self.ns+1):self.nr*(self.ns+2)]) * slope * 100.\n",
    "        w_in_Ea = tf.clip_by_value(w_in_Ea, 0., 300.)\n",
    "        w_in_Ea = tf.reshape(w_in_Ea, shape=(1,8))\n",
    "\n",
    "        w_in_b = tf.abs(p[self.nr*(self.ns+2):self.nr*(self.ns+3)])\n",
    "        w_in_b = tf.reshape(w_in_b, shape=(1,8))\n",
    "\n",
    "        w_in_ocen = tf.abs(p[self.nr*(self.ns+3):self.nr*(self.ns+4)])\n",
    "        w_in_ocen = tf.clip_by_value(w_in_ocen, 0., 1.5)\n",
    "        w_in_ocen = tf.reshape(w_in_ocen, shape=(1,8))\n",
    "\n",
    "        # 此段省略\n",
    "        # julia原文：\n",
    "        # if p_cutoff > 0:\n",
    "        #     w_in_ocean[abs(w_in_ocean)<p_cutoff] = 0.0\n",
    "        \n",
    "        w_in = tf.concat([\n",
    "            tf.clip_by_value(w_out*(-1),0.,4.),\n",
    "            w_in_Ea,\n",
    "            w_in_b,\n",
    "            w_in_ocen\n",
    "        ], 0)\n",
    "\n",
    "        return w_in, w_b, w_out\n",
    "\n",
    "    # crnn计算方法\n",
    "    @tf.function\n",
    "    def crnn(self, t, u, p):\n",
    "        self.update_p(p)\n",
    "        logX = tf.dtypes.cast(tf.math.log(tf.reshape(tf.clip_by_value(u, self.lb, 10.), shape=(4,1))),tf.float64)\n",
    "        T = self.getsampletemp(t)\n",
    "        w_in_X = tf.matmul(tf.transpose(self.w_in), tf.concat([logX, self.R/T, tf.math.log(T), self.current_ocen],0))\n",
    "        du_dt = tf.matmul(self.w_out, tf.exp(tf.reshape(w_in_X, shape=(self.nr,1))+tf.reshape(self.w_b, shape=(self.nr,1))))\n",
    "        return du_dt\n",
    "\n",
    "    # 工具函数\n",
    "    @tf.function\n",
    "    def getsampletemp(self, t):\n",
    "        t = tf.dtypes.cast(t, tf.float64)\n",
    " \n",
    "        T1 = self.current_T0 + t * (self.current_beta/60.0)\n",
    "        HR = tf.constant(40.0/60.0, dtype=tf.float64)\n",
    "        T2 = self.current_beta + 273.0\n",
    "        \n",
    "        temp1 = self.current_beta + 273.0 + HR * (t - 999.0*60.0)\n",
    "        temp2 = tf.constant(370.0+273.0, dtype=tf.float64)\n",
    "        T3 = tf.cond(tf.greater(temp1, temp2), lambda:temp2, lambda:temp1)\n",
    " \n",
    "        temp3 = 370.0+273.0 + HR * (t-1059.0*60.0)\n",
    "        temp4 = tf.constant(500.0+273.0, dtype=tf.float64)\n",
    "        T4 = tf.cond(tf.greater(temp3, temp4), lambda:temp4, lambda:temp3)\n",
    "        \n",
    "        T_branch1 = tf.cond(tf.greater(t, 1059. * 60.), lambda: T4, lambda: T3)\n",
    "        T_branch2 = tf.cond(tf.greater(t, 999. * 60.), lambda: T_branch1, lambda:T2)\n",
    "        T = tf.cond(tf.greater(self.current_beta, 100), lambda: T_branch2, lambda: T1)\n",
    "\n",
    "        return tf.reshape(T,shape=(1,1))\n",
    "\n",
    "    @tf.function\n",
    "    def pred_n_ode(self, p):\n",
    "        solution = tf.function(lambda: tfp.math.ode.BDF().solve(\n",
    "            self.crnn,\n",
    "            self.current_tinit,#t_init\n",
    "            self.u0,\n",
    "            solution_times=self.current_ts,\n",
    "            constants={'p': p}\n",
    "        ), autograph=True)()\n",
    "        return solution.states\n",
    "\n",
    "    @tf.function\n",
    "    def loss_n_ode(self, p):\n",
    "        u_pred = self.pred_n_ode(p)\n",
    "        \n",
    "        masslist = tf.reduce_sum(tf.clip_by_value(u_pred[:-1,:], 0, 1e3),axis=0)\n",
    "        gaslist = tf.clip_by_value(u_pred[-1:,:], 0, 1e3)\n",
    "\n",
    "        loss = tf.keras.losses.MAE(masslist, self.current_exp_data[:tf.size(masslist),2])\n",
    "        loss = tf.cond(tf.greater(self.current_ocen, 1000.0), lambda: loss, \\\n",
    "            lambda:loss + tf.keras.losses.MAE(gaslist, (1-self.current_exp_data[:tf.size(masslist),2])))\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-24e2a624da80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnpara\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mns\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpara\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.e-2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m0.8\u001b[0m \u001b[1;31m# w_b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# nr~nr*(ns+1) vij\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#p = tf.Variable(np.loadtxt(\"p.txt\"), dtype=tf.float64)\n",
    "nr=8\n",
    "ns=4\n",
    "npara = nr * (ns + 4) + 1\n",
    "p = np.random.randn(npara) * 1.e-2\n",
    "p[:nr] += 0.8 # w_b\n",
    "# nr~nr*(ns+1) vij\n",
    "p[nr*(ns+1):nr*(ns+2)] += 0.8 # w_out\n",
    "p[nr*(ns+2):nr*(ns+4)] += 0.1 # w_b | w_Ea\n",
    "p[-1] = 0.1 # slope\n",
    "\n",
    "p = tf.Variable(p, dtype=tf.float64)\n",
    "modeltest = CRNN(p)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
      "WARNING:tensorflow:From C:\\Users\\marcl\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_probability\\python\\math\\ode\\base.py:459: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
      "0 tf.Tensor(\n",
      "[23.52602274 23.52594089 23.52580028 23.52568981 23.52556986 23.52545896\n",
      " 23.52535718 23.52523863 23.52512243 23.52505017 23.52498742 23.52491737\n",
      " 23.52479439 23.52472008 23.5246304  23.52450188 23.524439   23.5243243\n",
      " 23.52419764 23.5240485  23.52390281 23.52379693 23.52361133 23.52347325\n",
      " 23.52329099 23.52308016 23.52287183 23.52268013 23.52242034 23.52210548\n",
      " 23.52179544 23.52147178 23.52116682 23.52088682 23.52054051 23.52018938\n",
      " 23.51983813 23.51947325 23.51908104 23.51871613 23.5183697  23.5179856\n",
      " 23.51761559 23.51723656 23.51685744 23.51648121 23.51610489 23.5157285\n",
      " 23.51535203 23.51497549 23.5145612  23.51418451 23.51380776 23.51343094\n",
      " 23.5130464  23.51340449 23.51381919 23.51419625 23.51457337 23.51495054\n",
      " 23.51532775 23.51570502 23.51608234 23.51649744 23.51687486 23.51725231\n",
      " 23.51766757 23.51804512 23.51842271 23.51887587 23.51921578], shape=(71,), dtype=float64)\n",
      "1 tf.Tensor(\n",
      "[23.52602274 23.52594089 23.52580028 23.52568981 23.52556986 23.52545896\n",
      " 23.52535718 23.52523863 23.52512243 23.52505017 23.52498742 23.52491737\n",
      " 23.52479439 23.52472008 23.5246304  23.52450188 23.524439   23.5243243\n",
      " 23.52419764 23.5240485  23.52390281 23.52379693 23.52361133 23.52347325\n",
      " 23.52329099 23.52308016 23.52287183 23.52268013 23.52242034 23.52210548\n",
      " 23.52179544 23.52147178 23.52116682 23.52088682 23.52054051 23.52018938\n",
      " 23.51983813 23.51947325 23.51908104 23.51871613 23.5183697  23.5179856\n",
      " 23.51761559 23.51723656 23.51685744 23.51648121 23.51610489 23.5157285\n",
      " 23.51535203 23.51497549 23.5145612  23.51418451 23.51380776 23.51343094\n",
      " 23.5130464  23.51340449 23.51381919 23.51419625 23.51457337 23.51495054\n",
      " 23.51532775 23.51570502 23.51608234 23.51649744 23.51687486 23.51725231\n",
      " 23.51766757 23.51804512 23.51842271 23.51887587 23.51921578], shape=(71,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "grad_norm = tf.zeros(shape=(modeltest.n_exp,), dtype=tf.float64)\n",
    "grad_norm = tf.Variable(grad_norm)\n",
    "exp_list = np.array(modeltest.l_exp)\n",
    "np.random.shuffle(exp_list)\n",
    "for epoches in range(100):\n",
    "    for i_exp in exp_list:\n",
    "        if i_exp in modeltest.l_val:\n",
    "            continue\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            modeltest.select_exp(i_exp)\n",
    "            tape.watch(p)\n",
    "            modeltest.update_p(p)\n",
    "            loss = modeltest.loss_n_ode(p)\n",
    "        \n",
    "        grad = tape.gradient(loss, p)\n",
    "        grad_norm_val = tf.norm(grad, ord=2)\n",
    "        grad = tf.cond(tf.greater(grad_norm_val, modeltest.grad_max), lambda: (grad / grad_norm_val) * modeltest.grad_max, lambda: grad)\n",
    "        opt.apply_gradients(zip([grad], [p]))\n",
    "    print(epoches, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sum:0\", shape=(4,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    modeltest.select_exp(i_exp)\n",
    "    tape.watch(p)\n",
    "    modeltest.update_p(p)\n",
    "    loss = modeltest.loss_n_ode(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float64, numpy=array([14.50651871])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
